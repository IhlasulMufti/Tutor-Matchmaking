{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Genders</th>\n",
       "      <th>Age Ranges</th>\n",
       "      <th>Specialization</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Math Tutor</th>\n",
       "      <th>Science Tutor</th>\n",
       "      <th>Social Tutor</th>\n",
       "      <th>Technology Tutor</th>\n",
       "      <th>Music Tutor</th>\n",
       "      <th>...</th>\n",
       "      <th>CSN1</th>\n",
       "      <th>CSN2</th>\n",
       "      <th>CSN3</th>\n",
       "      <th>CSN4</th>\n",
       "      <th>CSN5</th>\n",
       "      <th>OPN1</th>\n",
       "      <th>OPN2</th>\n",
       "      <th>OPN3</th>\n",
       "      <th>OPN4</th>\n",
       "      <th>OPN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novia Rizki Wulandari</td>\n",
       "      <td>1</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Flutter</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nabhan Nabilah</td>\n",
       "      <td>1</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Patung</td>\n",
       "      <td>Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herlina Kusyanuri Putri</td>\n",
       "      <td>1</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Digital Arts</td>\n",
       "      <td>Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rifdah Alyaa</td>\n",
       "      <td>1</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salsabilla</td>\n",
       "      <td>1</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Krita</td>\n",
       "      <td>Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Usamah</td>\n",
       "      <td>0</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Pendidikan Kewarganegaraan</td>\n",
       "      <td>Social</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Helena</td>\n",
       "      <td>1</td>\n",
       "      <td>17 - 25</td>\n",
       "      <td>Photoshop</td>\n",
       "      <td>Multimedia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Deva</td>\n",
       "      <td>1</td>\n",
       "      <td>26-34</td>\n",
       "      <td>Sejarah Dunia</td>\n",
       "      <td>Social</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dzaky</td>\n",
       "      <td>0</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Biologi</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Biru</td>\n",
       "      <td>1</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Fisika</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Names  Genders Age Ranges              Specialization   \n",
       "0     Novia Rizki Wulandari         1      17-25                     Flutter  \\\n",
       "1             Nabhan Nabilah        1      17-25                      Patung   \n",
       "2    Herlina Kusyanuri Putri        1      17-25                Digital Arts   \n",
       "3               Rifdah Alyaa        1      17-25             Web Development   \n",
       "4                 Salsabilla        1      17-25                       Krita   \n",
       "..                       ...      ...        ...                         ...   \n",
       "96                    Usamah        0      17-25  Pendidikan Kewarganegaraan   \n",
       "97                    Helena        1    17 - 25                   Photoshop   \n",
       "98                      Deva        1      26-34               Sejarah Dunia   \n",
       "99                     Dzaky        0      17-25                     Biologi   \n",
       "100                     Biru        1      17-25                      Fisika   \n",
       "\n",
       "     Categories  Math Tutor  Science Tutor  Social Tutor  Technology Tutor   \n",
       "0    Technology           0              0             0                 1  \\\n",
       "1          Arts           0              0             0                 0   \n",
       "2          Arts           0              0             0                 0   \n",
       "3    Technology           0              0             0                 1   \n",
       "4          Arts           0              0             0                 0   \n",
       "..          ...         ...            ...           ...               ...   \n",
       "96       Social           0              0             1                 0   \n",
       "97   Multimedia           0              0             0                 0   \n",
       "98       Social           0              0             1                 0   \n",
       "99      Science           0              1             0                 0   \n",
       "100     Science           0              1             0                 0   \n",
       "\n",
       "     Music Tutor  ...  CSN1  CSN2  CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4   \n",
       "0              0  ...     5     4     4     5     5     4     4     2     4  \\\n",
       "1              0  ...     5     2     5     5     5     2     2     5     5   \n",
       "2              0  ...     5     5     5     5     5     4     3     3     4   \n",
       "3              0  ...     2     3     2     3     4     3     2     3     4   \n",
       "4              0  ...     4     3     3     4     4     2     2     2     4   \n",
       "..           ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "96             0  ...     5     5     4     5     5     4     4     5     5   \n",
       "97             0  ...     4     3     4     4     4     3     4     2     5   \n",
       "98             0  ...     4     4     4     3     4     3     4     2     4   \n",
       "99             0  ...     5     5     5     5     5     5     5     5     4   \n",
       "100            0  ...     4     3     3     4     2     4     3     3     3   \n",
       "\n",
       "     OPN5  \n",
       "0       4  \n",
       "1       2  \n",
       "2       3  \n",
       "3       3  \n",
       "4       2  \n",
       "..    ...  \n",
       "96      5  \n",
       "97      4  \n",
       "98      3  \n",
       "99      5  \n",
       "100     3  \n",
       "\n",
       "[101 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv('data/clean_data.csv')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value?  False\n",
      "How many missing values?  0\n"
     ]
    }
   ],
   "source": [
    "# Check that we not missing any value after combine columns\n",
    "print('Is there any missing value? ', clean_df.isnull().values.any())\n",
    "print('How many missing values? ', clean_df.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy origin user data into match data to use in cluster\n",
    "match_df = clean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genders</th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EST1</th>\n",
       "      <th>EST2</th>\n",
       "      <th>EST3</th>\n",
       "      <th>EST4</th>\n",
       "      <th>...</th>\n",
       "      <th>CSN1</th>\n",
       "      <th>CSN2</th>\n",
       "      <th>CSN3</th>\n",
       "      <th>CSN4</th>\n",
       "      <th>CSN5</th>\n",
       "      <th>OPN1</th>\n",
       "      <th>OPN2</th>\n",
       "      <th>OPN3</th>\n",
       "      <th>OPN4</th>\n",
       "      <th>OPN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Genders  EXT1  EXT2  EXT3  EXT4  EXT5  EST1  EST2  EST3  EST4  ...  CSN1   \n",
       "0          1     4     2     4     4     3     3     3     1     2  ...     5  \\\n",
       "1          1     1     3     4     3     2     5     5     5     3  ...     5   \n",
       "2          1     3     3     1     1     2     2     4     4     5  ...     5   \n",
       "3          1     3     4     2     1     2     3     2     2     4  ...     2   \n",
       "4          1     2     4     4     2     2     2     5     4     4  ...     4   \n",
       "..       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "96         0     4     4     5     4     2     2     4     4     4  ...     5   \n",
       "97         1     3     4     2     2     2     5     5     4     5  ...     4   \n",
       "98         1     4     4     4     4     4     2     3     2     4  ...     4   \n",
       "99         0     4     5     5     5     5     1     1     1     1  ...     5   \n",
       "100        1     3     2     3     3     1     4     5     4     4  ...     4   \n",
       "\n",
       "     CSN2  CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4  OPN5  \n",
       "0       4     4     5     5     4     4     2     4     4  \n",
       "1       2     5     5     5     2     2     5     5     2  \n",
       "2       5     5     5     5     4     3     3     4     3  \n",
       "3       3     2     3     4     3     2     3     4     3  \n",
       "4       3     3     4     4     2     2     2     4     2  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "96      5     4     5     5     4     4     5     5     5  \n",
       "97      3     4     4     4     3     4     2     5     4  \n",
       "98      4     4     3     4     3     4     2     4     3  \n",
       "99      5     5     5     5     5     5     5     4     5  \n",
       "100     3     3     4     2     4     3     3     3     3  \n",
       "\n",
       "[101 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Column that not use for clustering match\n",
    "match_df.drop([\n",
    "    'Names',\n",
    "    'Age Ranges',\n",
    "    'Specialization',\n",
    "    'Categories',\n",
    "    'Math Tutor',\n",
    "    'Science Tutor',\n",
    "    'Social Tutor',\n",
    "    'Technology Tutor',\n",
    "    'Music Tutor',\n",
    "    'Arts Tutor',\n",
    "    'Multimedia Tutor',\n",
    "    'Language Tutor'\n",
    "], axis=1, inplace=True)\n",
    "\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_array = match_df.values\n",
    "match_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build PCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Size (1 Genders + 25 Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAModel(tf.Module):\n",
    "    def __init__(self, x_mean, components):\n",
    "        super(PCAModel, self).__init__()\n",
    "        self.x_mean = tf.Variable(x_mean, trainable=False)\n",
    "        self.components = tf.Variable(components, trainable=False)\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 26), dtype=tf.float32)])\n",
    "    def scale_features(self, x):\n",
    "        x_min = tf.reduce_min(x, axis=0)\n",
    "        x_max = tf.reduce_max(x, axis=0)\n",
    "\n",
    "        # Handle columns with zero variance\n",
    "        zero_variance_mask = tf.math.equal(x_min, x_max)\n",
    "        non_zero_variance_mask = tf.math.logical_not(zero_variance_mask)\n",
    "\n",
    "        # Scale the columns with non-zero variance\n",
    "        x_scaled_non_zero = tf.where(non_zero_variance_mask, (x - x_min) / (x_max - x_min), x)\n",
    "\n",
    "        # Scale the columns with zero variance\n",
    "        x_scaled_zero = tf.where(zero_variance_mask, tf.zeros_like(x), x_scaled_non_zero)\n",
    "\n",
    "        return x_scaled_zero\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 26), dtype=tf.float32)])\n",
    "    def apply_pca(self, x):\n",
    "        x_scaled = self.scale_features(x)\n",
    "        x_centered = x_scaled - self.x_mean\n",
    "        \n",
    "        # Compute the covariance matrix\n",
    "        covariance_matrix = tf.matmul(tf.transpose(x_centered), x_centered) / tf.cast(tf.shape(x_centered)[0], dtype=tf.float32)\n",
    "\n",
    "        # Perform eigenvalue decomposition\n",
    "        eigenvalues, eigenvectors = tf.linalg.eigh(covariance_matrix)\n",
    "        \n",
    "        # Sort eigenvectors based on eigenvalues\n",
    "        sorted_indices = tf.argsort(eigenvalues, direction='DESCENDING')\n",
    "        sorted_eigenvectors = tf.gather(eigenvectors, sorted_indices, axis=1)\n",
    "        \n",
    "        # Select the top k eigenvectors\n",
    "        k = tf.minimum(tf.shape(sorted_eigenvectors)[1], 2)  # Choose the top 2 eigenvectors (modify as needed)\n",
    "        selected_eigenvectors = sorted_eigenvectors[:, :k]\n",
    "        \n",
    "        # Project the centered data onto the selected eigenvectors\n",
    "        x_pca = tf.matmul(x_centered, selected_eigenvectors)\n",
    "        \n",
    "        return x_pca\n",
    "\n",
    "# Convert the numpy array to a TensorFlow tensor\n",
    "x_tf = tf.convert_to_tensor(match_array, dtype=tf.float32)\n",
    "\n",
    "# Perform PCA with k=2 (reduce to 2 dimensions)\n",
    "x_mean = tf.reduce_mean(x_tf, axis=0)\n",
    "_, _, V = tf.linalg.svd(x_tf - x_mean)\n",
    "components = V[:, :2]\n",
    "\n",
    "# Create an instance of the PCA model\n",
    "pca_model = PCAModel(x_mean, components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pca_matching/1/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the PCAModel as a SavedModel\n",
    "tf.saved_model.save(\n",
    "    pca_model,\n",
    "    export_dir='pca_matching/1/',\n",
    "    signatures={\n",
    "        'serving_default': pca_model.apply_pca.get_concrete_function()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['x'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 26)\n",
      "        name: serving_default_x:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "The MetaGraph with tag set ['serve'] contains the following ops: {'Min', 'MatMul', 'RealDiv', 'Max', 'Identity', 'StatefulPartitionedCall', 'ReadVariableOp', 'StridedSlice', 'StringJoin', 'TopKV2', 'Select', 'Minimum', 'MergeV2Checkpoints', 'Shape', 'PartitionedCall', 'GatherV2', 'Equal', 'RestoreV2', 'SelectV2', 'Sub', 'Cast', 'AssignVariableOp', 'LogicalNot', 'VarHandleOp', 'NoOp', 'ShardedFilename', 'SaveV2', 'ZerosLike', 'Pack', 'StaticRegexFullMatch', 'Const', 'DisableCopyOnRead', 'Transpose', 'SelfAdjointEigV2', 'Placeholder'}\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: 'apply_pca'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          x: TensorSpec(shape=(None, 26), dtype=tf.float32, name='x')\n",
      "\n",
      "  Function Name: 'scale_features'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          x: TensorSpec(shape=(None, 26), dtype=tf.float32, name='x')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!saved_model_cli show --dir {'pca_matching/1/'} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Load Model Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PCA model\n",
    "loaded_model = tf.saved_model.load(\"pca_matching/1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.7317123e+01 -2.3841858e-07]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Generate a new data point\n",
    "new_data = np.random.rand(1, 26)\n",
    "new_data_tf = tf.convert_to_tensor(new_data, dtype=tf.float32)\n",
    "\n",
    "# Predict the PCA value using the loaded model\n",
    "pca_value = loaded_model.apply_pca(new_data_tf)\n",
    "\n",
    "# Print the PCA value\n",
    "print(pca_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.39438839e+01  5.32377958e-01]\n",
      " [-1.45698795e+01 -5.26659250e-01]\n",
      " [-1.41649723e+01 -3.27734053e-01]\n",
      " [-1.51571198e+01 -2.32190311e-01]\n",
      " [-1.43135509e+01 -6.38926327e-01]\n",
      " [-1.46237736e+01 -3.23504448e-01]\n",
      " [-1.46204863e+01  1.39741337e+00]\n",
      " [-1.42957735e+01  9.24311876e-02]\n",
      " [-1.48252268e+01  6.90632463e-01]\n",
      " [-1.41056833e+01  1.39918756e+00]\n",
      " [-1.50502930e+01 -2.03321099e-01]\n",
      " [-1.37643776e+01 -4.74078655e-02]\n",
      " [-1.47877121e+01  5.62712073e-01]\n",
      " [-1.40906258e+01  3.27989101e-01]\n",
      " [-1.43428383e+01 -2.48354018e-01]\n",
      " [-1.39249220e+01 -2.66317964e-01]\n",
      " [-1.43345509e+01 -1.28089309e-01]\n",
      " [-1.50016174e+01 -5.69202483e-01]\n",
      " [-1.48620472e+01  1.53260112e-01]\n",
      " [-1.44163818e+01 -4.84670997e-01]\n",
      " [-1.33084288e+01  8.72605085e-01]\n",
      " [-1.48473377e+01 -1.54488087e-02]\n",
      " [-1.46117048e+01  2.48815417e-01]\n",
      " [-1.43094215e+01  2.42372155e-01]\n",
      " [-1.46729240e+01 -5.11651695e-01]\n",
      " [-1.50562553e+01 -1.63586378e-01]\n",
      " [-1.44426651e+01  4.61732030e-01]\n",
      " [-1.49806805e+01 -8.21066499e-01]\n",
      " [-1.44169998e+01 -3.99802864e-01]\n",
      " [-1.36006012e+01  4.88046288e-01]\n",
      " [-1.49425392e+01  1.19336843e-01]\n",
      " [-1.49110909e+01  5.43873668e-01]\n",
      " [-1.41224718e+01 -7.75069475e-01]\n",
      " [-1.41566467e+01 -5.73082268e-01]\n",
      " [-1.45265131e+01  4.60861921e-02]\n",
      " [-1.49270287e+01 -2.75611877e-02]\n",
      " [-1.32806778e+01 -3.48328888e-01]\n",
      " [-1.42277184e+01 -2.75006294e-01]\n",
      " [-1.53136034e+01 -4.27317560e-01]\n",
      " [-1.44208527e+01 -3.48167717e-01]\n",
      " [-1.45696125e+01 -6.53877258e-02]\n",
      " [-1.48918247e+01 -6.91469729e-01]\n",
      " [-1.40040112e+01 -3.18229020e-01]\n",
      " [-1.44829321e+01 -5.96479177e-02]\n",
      " [-1.40518055e+01 -8.52292299e-01]\n",
      " [-1.54124784e+01  7.97948599e-01]\n",
      " [-1.30749483e+01  9.37837362e-03]\n",
      " [-1.37216120e+01 -3.30009997e-01]\n",
      " [-1.37371168e+01  3.57454300e-01]\n",
      " [-1.41946030e+01  8.53726864e-02]\n",
      " [-1.35170994e+01 -4.62241173e-02]\n",
      " [-1.44569149e+01 -1.25840068e-01]\n",
      " [-1.46895237e+01 -4.35544372e-01]\n",
      " [-1.42116766e+01 -1.41421974e-01]\n",
      " [-1.47373314e+01 -1.36042118e-01]\n",
      " [-1.39492407e+01 -4.43505049e-01]\n",
      " [-1.36216469e+01  9.79119539e-03]\n",
      " [-1.34983311e+01 -2.12515593e-02]\n",
      " [-1.51375275e+01 -8.18091631e-01]\n",
      " [-1.44761553e+01 -1.32187665e-01]\n",
      " [-1.48677244e+01 -6.29359126e-01]\n",
      " [-1.58969059e+01 -3.22927594e-01]\n",
      " [-1.47331772e+01  2.54338145e-01]\n",
      " [-1.42408276e+01  3.91019106e-01]\n",
      " [-1.42263680e+01 -2.67526388e-01]\n",
      " [-1.46438456e+01 -2.88684189e-01]\n",
      " [-1.50614319e+01 -2.26765990e-01]\n",
      " [-1.49999943e+01  1.22169256e-01]\n",
      " [-1.45756454e+01  3.48829746e-01]\n",
      " [-1.38900928e+01  3.25527191e-02]\n",
      " [-1.37548561e+01 -4.66104746e-02]\n",
      " [-1.47094145e+01  3.37759376e-01]\n",
      " [-1.47203674e+01  6.49888456e-01]\n",
      " [-1.45735798e+01  1.15645647e-01]\n",
      " [-1.48996201e+01  7.57964969e-01]\n",
      " [-1.42771425e+01 -2.14810193e-01]\n",
      " [-1.54575920e+01  1.08527660e-01]\n",
      " [-1.45183125e+01 -4.05200124e-01]\n",
      " [-1.37808943e+01  2.26474643e-01]\n",
      " [-1.43600988e+01  1.42199457e+00]\n",
      " [-1.45187550e+01  2.26364017e-01]\n",
      " [-1.40786076e+01 -5.10668874e-01]\n",
      " [-1.45528946e+01 -6.09368682e-01]\n",
      " [-1.42604923e+01 -4.16817546e-01]\n",
      " [-1.39548130e+01  5.70486069e-01]\n",
      " [-1.31749058e+01  1.93265200e-01]\n",
      " [-1.26197338e+01  2.29642034e-01]\n",
      " [-1.23238821e+01  4.84199524e-02]\n",
      " [-1.28203545e+01  4.31506157e-01]\n",
      " [-1.29253960e+01  4.32310104e-01]\n",
      " [-1.42496939e+01 -3.82393777e-01]\n",
      " [-1.40498638e+01 -1.76684797e-01]\n",
      " [-1.44626961e+01  2.63650298e-01]\n",
      " [-1.40257149e+01  6.42966032e-01]\n",
      " [-1.45821304e+01 -4.51058090e-01]\n",
      " [-1.36815033e+01  4.43994343e-01]\n",
      " [-1.31893826e+01  4.50145602e-01]\n",
      " [-1.36162281e+01 -7.94798493e-01]\n",
      " [-1.42294102e+01  3.25119495e-01]\n",
      " [-1.32265797e+01  1.70927668e+00]\n",
      " [-1.42954731e+01 -7.04874277e-01]], shape=(101, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Predict PCA Valuse Using Our Match/Users Datasets\n",
    "new_data_tf = tf.convert_to_tensor(match_array, dtype=tf.float32)\n",
    "\n",
    "# Predict the PCA value using the loaded model\n",
    "pca_value = loaded_model.apply_pca(new_data_tf)\n",
    "\n",
    "# Print the PCA value\n",
    "print(pca_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Matchmaking Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pca(match_array):\n",
    "    # Load the PCA model\n",
    "    loaded_model = tf.saved_model.load('pca_matching/1/')\n",
    "    new_data_tf = tf.convert_to_tensor(match_array, dtype=tf.float32)\n",
    "\n",
    "    # Predict the PCA value using the loaded model\n",
    "    pca_value = loaded_model.apply_pca(new_data_tf)\n",
    "    pca_value_arr = pca_value.numpy()\n",
    "    \n",
    "    return pca_value_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guides_idx_filtered(user_id, user_df):\n",
    "    # Get user destination and persona\n",
    "    user_destination = user_df.loc[user_id, 'Categories']\n",
    "\n",
    "    # Filter users with the same destination and roles value of 'guide'\n",
    "    filtered_users = user_df[(user_df['Categories'] == user_destination)]\n",
    "\n",
    "    user_indices = []\n",
    "    for idx in filtered_users.index:\n",
    "        user_indices.append(idx)\n",
    "    user_indices = [idx for idx in user_indices if idx != user_id]\n",
    "            \n",
    "    return user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchmaking(user_id, match_array, user_df):\n",
    "    \n",
    "    filtered_user_indices = get_guides_idx_filtered(user_id, user_df)\n",
    "    if len(filtered_user_indices) == 0:\n",
    "        print(\"No Results\")\n",
    "        sys.exit()\n",
    "        \n",
    "    user_indices = filtered_user_indices + [user_id]\n",
    "    \n",
    "    pca_data = predict_pca(match_array[user_indices])\n",
    "\n",
    "    distances = []\n",
    "    for idx in user_indices:\n",
    "        # Get the distances within the cluster of the specified user\n",
    "\n",
    "        distance_idx = euclidean_distances([pca_data[user_indices.index(user_id)]], [pca_data[user_indices.index(idx)]])\n",
    "        distances.append(distance_idx)\n",
    "\n",
    "    # Normalize the distances within the range of 0-100\n",
    "    normalized_distances = 1 - distances / np.max(distances)\n",
    "    scores = normalized_distances * 100\n",
    "    \n",
    "    # Reshape the list\n",
    "    scores = np.reshape(scores, (len(user_indices)))\n",
    "    \n",
    "    matches = []\n",
    "    for i in range(len(filtered_user_indices)):\n",
    "        matches.append((filtered_user_indices[i], scores[i]))\n",
    "    \n",
    "    # Sort the matches based on the highest score\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"User Index:\", user_id)\n",
    "    print(\"Matched Peers:\")\n",
    "    match_idx = [user_id]\n",
    "    for match_index, score in matches:\n",
    "        if user_df.iloc[match_index, 2] == user_df.iloc[user_id, 2]:\n",
    "            match_idx.append(match_index)\n",
    "            print(\"Index:\", match_index, \"| Score:\", f\"{score:.2f}%\")\n",
    "                \n",
    "    # Check if Destination and roles is correct \n",
    "    print()         \n",
    "    print(user_df.iloc[match_idx, [0, 1, 3, 4]])\n",
    "    \n",
    "    # Check if they get same preference\n",
    "    print()\n",
    "    print(user_df.iloc[match_idx, 5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Index: 0\n",
      "Matched Peers:\n",
      "Index: 34 | Score: 78.64%\n",
      "Index: 95 | Score: 49.28%\n",
      "Index: 28 | Score: 38.01%\n",
      "Index: 81 | Score: 32.34%\n",
      "Index: 94 | Score: 29.46%\n",
      "Index: 41 | Score: 6.40%\n",
      "Index: 3 | Score: 3.48%\n",
      "\n",
      "                     Names  Genders     Specialization  Categories\n",
      "0   Novia Rizki Wulandari         1            Flutter  Technology\n",
      "34                    Zeen        0  Backend Developer  Technology\n",
      "95                   Salma        1           HTML CSS  Technology\n",
      "28        Nur Alifia Riany        1            Android  Technology\n",
      "81     Lili Nandita Auliya        1      Multiplatform  Technology\n",
      "94                  Annisa        1            Laravel  Technology\n",
      "41                 Gustian        0              React  Technology\n",
      "3             Rifdah Alyaa        1    Web Development  Technology\n",
      "\n",
      "    Math Tutor  Science Tutor  Social Tutor  Technology Tutor  Music Tutor   \n",
      "0            0              0             0                 1            0  \\\n",
      "34           0              0             0                 1            0   \n",
      "95           0              0             0                 1            0   \n",
      "28           0              0             0                 1            0   \n",
      "81           0              0             0                 1            0   \n",
      "94           0              0             0                 1            0   \n",
      "41           0              0             0                 1            0   \n",
      "3            0              0             0                 1            0   \n",
      "\n",
      "    Arts Tutor  Multimedia Tutor  Language Tutor  EXT1  EXT2  ...  CSN1  CSN2   \n",
      "0            0                 0               0     4     2  ...     5     4  \\\n",
      "34           0                 0               0     2     2  ...     4     4   \n",
      "95           0                 0               0     2     1  ...     5     5   \n",
      "28           0                 0               0     1     3  ...     3     3   \n",
      "81           0                 0               0     1     4  ...     3     3   \n",
      "94           0                 0               0     3     3  ...     4     2   \n",
      "41           0                 0               0     3     2  ...     4     2   \n",
      "3            0                 0               0     3     4  ...     2     3   \n",
      "\n",
      "    CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4  OPN5  \n",
      "0      4     5     5     4     4     2     4     4  \n",
      "34     4     5     5     4     4     3     5     4  \n",
      "95     5     5     5     5     5     4     5     4  \n",
      "28     4     3     4     3     3     2     4     3  \n",
      "81     4     4     2     2     4     3     3     3  \n",
      "94     3     3     3     3     3     2     4     3  \n",
      "41     2     3     3     2     2     3     4     4  \n",
      "3      2     3     4     3     2     3     4     3  \n",
      "\n",
      "[8 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "matchmaking(0, match_array, clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Index: 58\n",
      "Matched Peers:\n",
      "Index: 25 | Score: 91.07%\n",
      "Index: 5 | Score: 74.95%\n",
      "Index: 83 | Score: 57.54%\n",
      "Index: 92 | Score: 55.38%\n",
      "Index: 8 | Score: 51.84%\n",
      "Index: 57 | Score: 27.30%\n",
      "Index: 13 | Score: 26.46%\n",
      "\n",
      "                 Names  Genders          Specialization  Categories\n",
      "58     Alyzar Aviandi         0          Penulisan Buku  Multimedia\n",
      "25              Elma N        1                   Excel  Multimedia\n",
      "5              Maulani        1               Fotografi  Multimedia\n",
      "83          Dhea Setya        1  Videografi dan Editing  Multimedia\n",
      "92                 FÃ©i        1            Editing Foto  Multimedia\n",
      "8                   JJ        1              Videografi  Multimedia\n",
      "57             kartika        1        Microsoft Office  Multimedia\n",
      "13  Bayu Daru Isnandar        0            Audio Mixing  Multimedia\n",
      "\n",
      "    Math Tutor  Science Tutor  Social Tutor  Technology Tutor  Music Tutor   \n",
      "58           0              0             0                 0            0  \\\n",
      "25           0              0             0                 0            0   \n",
      "5            0              0             0                 0            0   \n",
      "83           0              0             0                 0            0   \n",
      "92           0              0             0                 0            0   \n",
      "8            0              0             0                 0            0   \n",
      "57           0              0             0                 0            0   \n",
      "13           0              0             0                 0            0   \n",
      "\n",
      "    Arts Tutor  Multimedia Tutor  Language Tutor  EXT1  EXT2  ...  CSN1  CSN2   \n",
      "58           0                 1               0     1     2  ...     2     3  \\\n",
      "25           0                 1               0     3     3  ...     3     3   \n",
      "5            0                 1               0     2     3  ...     4     4   \n",
      "83           0                 1               0     3     4  ...     4     3   \n",
      "92           0                 1               0     3     3  ...     4     2   \n",
      "8            0                 1               0     2     3  ...     3     2   \n",
      "57           0                 1               0     4     4  ...     4     4   \n",
      "13           0                 1               0     3     4  ...     2     3   \n",
      "\n",
      "    CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4  OPN5  \n",
      "58     3     3     3     2     2     2     3     3  \n",
      "25     4     3     3     2     2     2     3     2  \n",
      "5      3     4     4     3     3     2     3     3  \n",
      "83     4     2     3     3     3     4     3     3  \n",
      "92     4     4     4     3     4     2     4     4  \n",
      "8      2     2     3     5     4     3     5     4  \n",
      "57     5     5     5     4     4     3     3     4  \n",
      "13     3     3     4     3     5     3     3     5  \n",
      "\n",
      "[8 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "matchmaking(58, match_array, clean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
