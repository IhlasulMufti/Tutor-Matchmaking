{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Genders</th>\n",
       "      <th>Age Ranges</th>\n",
       "      <th>Specialization</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Math Tutor</th>\n",
       "      <th>Science Tutor</th>\n",
       "      <th>Social Tutor</th>\n",
       "      <th>Technology Tutor</th>\n",
       "      <th>Music Tutor</th>\n",
       "      <th>...</th>\n",
       "      <th>CSN1</th>\n",
       "      <th>CSN2</th>\n",
       "      <th>CSN3</th>\n",
       "      <th>CSN4</th>\n",
       "      <th>CSN5</th>\n",
       "      <th>OPN1</th>\n",
       "      <th>OPN2</th>\n",
       "      <th>OPN3</th>\n",
       "      <th>OPN4</th>\n",
       "      <th>OPN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Novia Rizki Wulandari</td>\n",
       "      <td>Female</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Flutter</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nabhan Nabilah</td>\n",
       "      <td>Female</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Patung</td>\n",
       "      <td>Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herlina Kusyanuri Putri</td>\n",
       "      <td>Female</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Digital Arts</td>\n",
       "      <td>Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rifdah Alyaa</td>\n",
       "      <td>Female</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salsabilla</td>\n",
       "      <td>Female</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Krita</td>\n",
       "      <td>Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Usamah</td>\n",
       "      <td>Male</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Pendidikan Kewarganegaraan</td>\n",
       "      <td>Social</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Helena</td>\n",
       "      <td>Female</td>\n",
       "      <td>17 - 25</td>\n",
       "      <td>Photoshop</td>\n",
       "      <td>Multimedia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Deva</td>\n",
       "      <td>Female</td>\n",
       "      <td>26-34</td>\n",
       "      <td>Sejarah Dunia</td>\n",
       "      <td>Social</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dzaky</td>\n",
       "      <td>Male</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Biologi</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Biru</td>\n",
       "      <td>Female</td>\n",
       "      <td>17-25</td>\n",
       "      <td>Fisika</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Names Genders Age Ranges              Specialization   \n",
       "0     Novia Rizki Wulandari   Female      17-25                     Flutter  \\\n",
       "1             Nabhan Nabilah  Female      17-25                      Patung   \n",
       "2    Herlina Kusyanuri Putri  Female      17-25                Digital Arts   \n",
       "3               Rifdah Alyaa  Female      17-25             Web Development   \n",
       "4                 Salsabilla  Female      17-25                       Krita   \n",
       "..                       ...     ...        ...                         ...   \n",
       "96                    Usamah    Male      17-25  Pendidikan Kewarganegaraan   \n",
       "97                    Helena  Female    17 - 25                   Photoshop   \n",
       "98                      Deva  Female      26-34               Sejarah Dunia   \n",
       "99                     Dzaky    Male      17-25                     Biologi   \n",
       "100                     Biru  Female      17-25                      Fisika   \n",
       "\n",
       "     Categories  Math Tutor  Science Tutor  Social Tutor  Technology Tutor   \n",
       "0    Technology           0              0             0                 1  \\\n",
       "1          Arts           0              0             0                 0   \n",
       "2          Arts           0              0             0                 0   \n",
       "3    Technology           0              0             0                 1   \n",
       "4          Arts           0              0             0                 0   \n",
       "..          ...         ...            ...           ...               ...   \n",
       "96       Social           0              0             1                 0   \n",
       "97   Multimedia           0              0             0                 0   \n",
       "98       Social           0              0             1                 0   \n",
       "99      Science           0              1             0                 0   \n",
       "100     Science           0              1             0                 0   \n",
       "\n",
       "     Music Tutor  ...  CSN1  CSN2  CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4   \n",
       "0              0  ...     5     4     4     5     5     4     4     2     4  \\\n",
       "1              0  ...     5     2     5     5     5     2     2     5     5   \n",
       "2              0  ...     5     5     5     5     5     4     3     3     4   \n",
       "3              0  ...     2     3     2     3     4     3     2     3     4   \n",
       "4              0  ...     4     3     3     4     4     2     2     2     4   \n",
       "..           ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "96             0  ...     5     5     4     5     5     4     4     5     5   \n",
       "97             0  ...     4     3     4     4     4     3     4     2     5   \n",
       "98             0  ...     4     4     4     3     4     3     4     2     4   \n",
       "99             0  ...     5     5     5     5     5     5     5     5     4   \n",
       "100            0  ...     4     3     3     4     2     4     3     3     3   \n",
       "\n",
       "     OPN5  \n",
       "0       4  \n",
       "1       2  \n",
       "2       3  \n",
       "3       3  \n",
       "4       2  \n",
       "..    ...  \n",
       "96      5  \n",
       "97      4  \n",
       "98      3  \n",
       "99      5  \n",
       "100     3  \n",
       "\n",
       "[101 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv('data/clean_data.csv')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any missing value?  False\n",
      "How many missing values?  0\n"
     ]
    }
   ],
   "source": [
    "# Check that we not missing any value after combine columns\n",
    "print('Is there any missing value? ', clean_df.isnull().values.any())\n",
    "print('How many missing values? ', clean_df.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy origin user data into match data to use in cluster\n",
    "match_df = clean_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EST1</th>\n",
       "      <th>EST2</th>\n",
       "      <th>EST3</th>\n",
       "      <th>EST4</th>\n",
       "      <th>EST5</th>\n",
       "      <th>...</th>\n",
       "      <th>CSN1</th>\n",
       "      <th>CSN2</th>\n",
       "      <th>CSN3</th>\n",
       "      <th>CSN4</th>\n",
       "      <th>CSN5</th>\n",
       "      <th>OPN1</th>\n",
       "      <th>OPN2</th>\n",
       "      <th>OPN3</th>\n",
       "      <th>OPN4</th>\n",
       "      <th>OPN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EXT1  EXT2  EXT3  EXT4  EXT5  EST1  EST2  EST3  EST4  EST5  ...  CSN1   \n",
       "0       4     2     4     4     3     3     3     1     2     3  ...     5  \\\n",
       "1       1     3     4     3     2     5     5     5     3     2  ...     5   \n",
       "2       3     3     1     1     2     2     4     4     5     3  ...     5   \n",
       "3       3     4     2     1     2     3     2     2     4     3  ...     2   \n",
       "4       2     4     4     2     2     2     5     4     4     3  ...     4   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "96      4     4     5     4     2     2     4     4     4     4  ...     5   \n",
       "97      3     4     2     2     2     5     5     4     5     4  ...     4   \n",
       "98      4     4     4     4     4     2     3     2     4     3  ...     4   \n",
       "99      4     5     5     5     5     1     1     1     1     4  ...     5   \n",
       "100     3     2     3     3     1     4     5     4     4     4  ...     4   \n",
       "\n",
       "     CSN2  CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4  OPN5  \n",
       "0       4     4     5     5     4     4     2     4     4  \n",
       "1       2     5     5     5     2     2     5     5     2  \n",
       "2       5     5     5     5     4     3     3     4     3  \n",
       "3       3     2     3     4     3     2     3     4     3  \n",
       "4       3     3     4     4     2     2     2     4     2  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "96      5     4     5     5     4     4     5     5     5  \n",
       "97      3     4     4     4     3     4     2     5     4  \n",
       "98      4     4     3     4     3     4     2     4     3  \n",
       "99      5     5     5     5     5     5     5     4     5  \n",
       "100     3     3     4     2     4     3     3     3     3  \n",
       "\n",
       "[101 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Column that not use for clustering match\n",
    "match_df.drop([\n",
    "    'Names',\n",
    "    'Genders',\n",
    "    'Age Ranges',\n",
    "    'Specialization',\n",
    "    'Categories',\n",
    "    'Math Tutor',\n",
    "    'Science Tutor',\n",
    "    'Social Tutor',\n",
    "    'Technology Tutor',\n",
    "    'Music Tutor',\n",
    "    'Arts Tutor',\n",
    "    'Multimedia Tutor',\n",
    "    'Language Tutor'\n",
    "], axis=1, inplace=True)\n",
    "\n",
    "match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_array = match_df.values\n",
    "match_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build PCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Size (8 Categories + 25 Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAModel(tf.Module):\n",
    "    def __init__(self, x_mean, components):\n",
    "        super(PCAModel, self).__init__()\n",
    "        self.x_mean = tf.Variable(x_mean, trainable=False)\n",
    "        self.components = tf.Variable(components, trainable=False)\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 25), dtype=tf.float32)])\n",
    "    def scale_features(self, x):\n",
    "        x_min = tf.reduce_min(x, axis=0)\n",
    "        x_max = tf.reduce_max(x, axis=0)\n",
    "\n",
    "        # Handle columns with zero variance\n",
    "        zero_variance_mask = tf.math.equal(x_min, x_max)\n",
    "        non_zero_variance_mask = tf.math.logical_not(zero_variance_mask)\n",
    "\n",
    "        # Scale the columns with non-zero variance\n",
    "        x_scaled_non_zero = tf.where(non_zero_variance_mask, (x - x_min) / (x_max - x_min), x)\n",
    "\n",
    "        # Scale the columns with zero variance\n",
    "        x_scaled_zero = tf.where(zero_variance_mask, tf.zeros_like(x), x_scaled_non_zero)\n",
    "\n",
    "        return x_scaled_zero\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 25), dtype=tf.float32)])\n",
    "    def apply_pca(self, x):\n",
    "        x_scaled = self.scale_features(x)\n",
    "        x_centered = x_scaled - self.x_mean\n",
    "        \n",
    "        # Compute the covariance matrix\n",
    "        covariance_matrix = tf.matmul(tf.transpose(x_centered), x_centered) / tf.cast(tf.shape(x_centered)[0], dtype=tf.float32)\n",
    "\n",
    "        # Perform eigenvalue decomposition\n",
    "        eigenvalues, eigenvectors = tf.linalg.eigh(covariance_matrix)\n",
    "        \n",
    "        # Sort eigenvectors based on eigenvalues\n",
    "        sorted_indices = tf.argsort(eigenvalues, direction='DESCENDING')\n",
    "        sorted_eigenvectors = tf.gather(eigenvectors, sorted_indices, axis=1)\n",
    "        \n",
    "        # Select the top k eigenvectors\n",
    "        k = tf.minimum(tf.shape(sorted_eigenvectors)[1], 2)  # Choose the top 2 eigenvectors (modify as needed)\n",
    "        selected_eigenvectors = sorted_eigenvectors[:, :k]\n",
    "        \n",
    "        # Project the centered data onto the selected eigenvectors\n",
    "        x_pca = tf.matmul(x_centered, selected_eigenvectors)\n",
    "        \n",
    "        return x_pca\n",
    "\n",
    "# Convert the numpy array to a TensorFlow tensor\n",
    "x_tf = tf.convert_to_tensor(match_array, dtype=tf.float32)\n",
    "\n",
    "# Perform PCA with k=2 (reduce to 2 dimensions)\n",
    "x_mean = tf.reduce_mean(x_tf, axis=0)\n",
    "_, _, V = tf.linalg.svd(x_tf - x_mean)\n",
    "components = V[:, :2]\n",
    "\n",
    "# Create an instance of the PCA model\n",
    "pca_model = PCAModel(x_mean, components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pca_matching/1/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the PCAModel as a SavedModel\n",
    "tf.saved_model.save(\n",
    "    pca_model,\n",
    "    export_dir='pca_matching/1/',\n",
    "    signatures={\n",
    "        'serving_default': pca_model.apply_pca.get_concrete_function()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['x'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 25)\n",
      "        name: serving_default_x:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "The MetaGraph with tag set ['serve'] contains the following ops: {'Shape', 'RestoreV2', 'Minimum', 'StridedSlice', 'Const', 'Identity', 'Pack', 'Cast', 'SaveV2', 'ShardedFilename', 'Sub', 'Equal', 'NoOp', 'MergeV2Checkpoints', 'MatMul', 'Select', 'DisableCopyOnRead', 'StringJoin', 'StatefulPartitionedCall', 'PartitionedCall', 'ZerosLike', 'SelfAdjointEigV2', 'StaticRegexFullMatch', 'RealDiv', 'Placeholder', 'AssignVariableOp', 'Max', 'Transpose', 'Min', 'VarHandleOp', 'GatherV2', 'LogicalNot', 'TopKV2', 'SelectV2', 'ReadVariableOp'}\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: 'apply_pca'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          x: TensorSpec(shape=(None, 25), dtype=tf.float32, name='x')\n",
      "\n",
      "  Function Name: 'scale_features'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          x: TensorSpec(shape=(None, 25), dtype=tf.float32, name='x')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!saved_model_cli show --dir {'pca_matching/1/'} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Load Model Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PCA model\n",
    "loaded_model = tf.saved_model.load(\"pca_matching/1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.7302851e+01  1.7285347e-06]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Generate a new data point\n",
    "new_data = np.random.rand(1, 25)\n",
    "new_data_tf = tf.convert_to_tensor(new_data, dtype=tf.float32)\n",
    "\n",
    "# Predict the PCA value using the loaded model\n",
    "pca_value = loaded_model.apply_pca(new_data_tf)\n",
    "\n",
    "# Print the PCA value\n",
    "print(pca_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.39439363e+01 -6.07908845e-01]\n",
      " [-1.45699320e+01  4.69947815e-01]\n",
      " [-1.41650257e+01  2.57207811e-01]\n",
      " [-1.51571732e+01  1.74559951e-01]\n",
      " [-1.43136015e+01  5.91525495e-01]\n",
      " [-1.46238260e+01  2.65632689e-01]\n",
      " [-1.46203651e+01 -1.28318977e+00]\n",
      " [-1.42956524e+01  3.33956480e-02]\n",
      " [-1.48252792e+01 -7.42141604e-01]\n",
      " [-1.41055622e+01 -1.28963482e+00]\n",
      " [-1.50503464e+01  1.80672199e-01]\n",
      " [-1.37644310e+01 -6.68561459e-03]\n",
      " [-1.47875919e+01 -4.49428916e-01]\n",
      " [-1.40905056e+01 -1.79685324e-01]\n",
      " [-1.43428917e+01  2.04492390e-01]\n",
      " [-1.39249744e+01  2.09402472e-01]\n",
      " [-1.43344326e+01  2.50321805e-01]\n",
      " [-1.50014973e+01  7.13888407e-01]\n",
      " [-1.48621006e+01 -2.30364442e-01]\n",
      " [-1.44162626e+01  6.29514754e-01]\n",
      " [-1.33084812e+01 -9.43474054e-01]\n",
      " [-1.48472157e+01  1.18019998e-01]\n",
      " [-1.46117573e+01 -3.06396008e-01]\n",
      " [-1.43094740e+01 -3.00646216e-01]\n",
      " [-1.46729774e+01  4.69605863e-01]\n",
      " [-1.50563078e+01  1.06678903e-01]\n",
      " [-1.44427176e+01 -5.26892722e-01]\n",
      " [-1.49807339e+01  7.82000184e-01]\n",
      " [-1.44170532e+01  3.52931798e-01]\n",
      " [-1.36006536e+01 -5.64140916e-01]\n",
      " [-1.49425926e+01 -1.80943459e-01]\n",
      " [-1.49109688e+01 -4.23822880e-01]\n",
      " [-1.41225243e+01  7.35277534e-01]\n",
      " [-1.41566992e+01  5.24919152e-01]\n",
      " [-1.45263939e+01  4.60660160e-02]\n",
      " [-1.49270802e+01 -3.79146934e-02]\n",
      " [-1.32807293e+01  2.98510462e-01]\n",
      " [-1.42277699e+01  2.15630919e-01]\n",
      " [-1.53136559e+01  3.79286259e-01]\n",
      " [-1.44207325e+01  4.93373454e-01]\n",
      " [-1.45694923e+01  1.95601493e-01]\n",
      " [-1.48917046e+01  8.39077234e-01]\n",
      " [-1.40040646e+01  2.71244586e-01]\n",
      " [-1.44829845e+01  9.90366936e-03]\n",
      " [-1.40518570e+01  8.01253200e-01]\n",
      " [-1.54125309e+01 -8.50650787e-01]\n",
      " [-1.30750008e+01 -6.25997484e-02]\n",
      " [-1.37216644e+01  2.91277438e-01]\n",
      " [-1.37371702e+01 -4.12559360e-01]\n",
      " [-1.41946564e+01 -1.57333434e-01]\n",
      " [-1.35171537e+01 -1.24954581e-02]\n",
      " [-1.44567938e+01  2.66252041e-01]\n",
      " [-1.46895771e+01  3.83980662e-01]\n",
      " [-1.42117290e+01  8.92747939e-02]\n",
      " [-1.47372112e+01  2.70446002e-01]\n",
      " [-1.39492950e+01  4.05653089e-01]\n",
      " [-1.36216984e+01 -6.09026253e-02]\n",
      " [-1.34983835e+01 -3.52828205e-02]\n",
      " [-1.51374073e+01  9.57032681e-01]\n",
      " [-1.44762077e+01  8.45644772e-02]\n",
      " [-1.48676033e+01  7.75994778e-01]\n",
      " [-1.58969584e+01  2.79075235e-01]\n",
      " [-1.47330570e+01 -1.42711997e-01]\n",
      " [-1.42408810e+01 -4.51569110e-01]\n",
      " [-1.42264194e+01  2.27616370e-01]\n",
      " [-1.46437263e+01  4.29544866e-01]\n",
      " [-1.50614853e+01  1.60902500e-01]\n",
      " [-1.49998741e+01  3.12066078e-03]\n",
      " [-1.45755243e+01 -2.26376534e-01]\n",
      " [-1.38901453e+01 -9.47413146e-02]\n",
      " [-1.37547350e+01  1.85819745e-01]\n",
      " [-1.47094669e+01 -4.15550679e-01]\n",
      " [-1.47204208e+01 -7.10198879e-01]\n",
      " [-1.45736332e+01 -1.67542040e-01]\n",
      " [-1.48996725e+01 -8.21588278e-01]\n",
      " [-1.42771969e+01  1.74486041e-01]\n",
      " [-1.54574728e+01  4.99551594e-02]\n",
      " [-1.45183640e+01  3.50644290e-01]\n",
      " [-1.37807732e+01 -1.07453436e-01]\n",
      " [-1.43599787e+01 -1.30964601e+00]\n",
      " [-1.45188093e+01 -2.83437252e-01]\n",
      " [-1.40786600e+01  4.78598058e-01]\n",
      " [-1.45529480e+01  5.62650979e-01]\n",
      " [-1.42605457e+01  3.70723128e-01]\n",
      " [-1.39548655e+01 -6.41939044e-01]\n",
      " [-1.31749573e+01 -2.61792630e-01]\n",
      " [-1.26196136e+01 -1.02795750e-01]\n",
      " [-1.23239346e+01 -9.93390977e-02]\n",
      " [-1.28204069e+01 -4.84983355e-01]\n",
      " [-1.29254494e+01 -4.89553362e-01]\n",
      " [-1.42497473e+01  3.32000643e-01]\n",
      " [-1.40497437e+01  3.10128868e-01]\n",
      " [-1.44627485e+01 -3.26023847e-01]\n",
      " [-1.40257673e+01 -7.18970299e-01]\n",
      " [-1.45821838e+01  4.03447986e-01]\n",
      " [-1.36815567e+01 -5.09009957e-01]\n",
      " [-1.31892605e+01 -3.32637221e-01]\n",
      " [-1.36162815e+01  7.51461387e-01]\n",
      " [-1.42294636e+01 -3.88511240e-01]\n",
      " [-1.32264585e+01 -1.60673964e+00]\n",
      " [-1.42955265e+01  6.63682401e-01]], shape=(101, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Predict PCA Valuse Using Our Match/Users Datasets\n",
    "new_data_tf = tf.convert_to_tensor(match_array, dtype=tf.float32)\n",
    "\n",
    "# Predict the PCA value using the loaded model\n",
    "pca_value = loaded_model.apply_pca(new_data_tf)\n",
    "\n",
    "# Print the PCA value\n",
    "print(pca_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Matchmaking Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pca(match_array):\n",
    "    # Load the PCA model\n",
    "    loaded_model = tf.saved_model.load('pca_matching/1/')\n",
    "    new_data_tf = tf.convert_to_tensor(match_array, dtype=tf.float32)\n",
    "\n",
    "    # Predict the PCA value using the loaded model\n",
    "    pca_value = loaded_model.apply_pca(new_data_tf)\n",
    "    pca_value_arr = pca_value.numpy()\n",
    "    \n",
    "    return pca_value_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guides_idx_filtered(user_id, user_df):\n",
    "    # Get user destination and persona\n",
    "    user_destination = user_df.loc[user_id, 'Categories']\n",
    "\n",
    "    # Filter users with the same destination and roles value of 'guide'\n",
    "    filtered_users = user_df[(user_df['Categories'] == user_destination)]\n",
    "\n",
    "    user_indices = []\n",
    "    for idx in filtered_users.index:\n",
    "        user_indices.append(idx)\n",
    "    user_indices = [idx for idx in user_indices if idx != user_id]\n",
    "            \n",
    "    return user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchmaking(user_id, match_array, user_df):\n",
    "    \n",
    "    filtered_user_indices = get_guides_idx_filtered(user_id, user_df)\n",
    "    if len(filtered_user_indices) == 0:\n",
    "        print(\"No Results\")\n",
    "        sys.exit()\n",
    "        \n",
    "    user_indices = filtered_user_indices + [user_id]\n",
    "    \n",
    "    pca_data = predict_pca(match_array[user_indices])\n",
    "\n",
    "    distances = []\n",
    "    for idx in user_indices:\n",
    "        # Get the distances within the cluster of the specified user\n",
    "\n",
    "        distance_idx = euclidean_distances([pca_data[user_indices.index(user_id)]], [pca_data[user_indices.index(idx)]])\n",
    "        distances.append(distance_idx)\n",
    "\n",
    "    # Normalize the distances within the range of 0-100\n",
    "    normalized_distances = 1 - distances / np.max(distances)\n",
    "    scores = normalized_distances * 100\n",
    "    \n",
    "    # Reshape the list\n",
    "    scores = np.reshape(scores, (len(user_indices)))\n",
    "    \n",
    "    matches = []\n",
    "    for i in range(len(filtered_user_indices)):\n",
    "        matches.append((filtered_user_indices[i], scores[i]))\n",
    "    \n",
    "    # Sort the matches based on the highest score\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"User Index:\", user_id)\n",
    "    print(\"Matched Peers:\")\n",
    "    match_idx = [user_id]\n",
    "    for match_index, score in matches:\n",
    "        if user_df.iloc[match_index, 2] == user_df.iloc[user_id, 2]:\n",
    "            match_idx.append(match_index)\n",
    "            print(\"Index:\", match_index, \"| Score:\", f\"{score:.2f}%\")\n",
    "                \n",
    "    # Check if Destination and roles is correct \n",
    "    print()         \n",
    "    print(user_df.iloc[match_idx, [0, 1, 2, 3, 4]])\n",
    "    \n",
    "    # Check if they get same preference\n",
    "    print()\n",
    "    print(user_df.iloc[match_idx, 5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Index: 0\n",
      "Matched Peers:\n",
      "Index: 34 | Score: 77.37%\n",
      "Index: 95 | Score: 46.74%\n",
      "Index: 28 | Score: 38.69%\n",
      "Index: 81 | Score: 33.87%\n",
      "Index: 94 | Score: 29.72%\n",
      "Index: 3 | Score: 2.83%\n",
      "Index: 41 | Score: 0.68%\n",
      "\n",
      "                     Names Genders Age Ranges     Specialization  Categories\n",
      "0   Novia Rizki Wulandari   Female      17-25            Flutter  Technology\n",
      "34                    Zeen    Male      17-25  Backend Developer  Technology\n",
      "95                   Salma  Female      17-25           HTML CSS  Technology\n",
      "28        Nur Alifia Riany  Female      17-25            Android  Technology\n",
      "81     Lili Nandita Auliya  Female      17-25      Multiplatform  Technology\n",
      "94                  Annisa  Female      17-25            Laravel  Technology\n",
      "3             Rifdah Alyaa  Female      17-25    Web Development  Technology\n",
      "41                 Gustian    Male      17-25              React  Technology\n",
      "\n",
      "    Math Tutor  Science Tutor  Social Tutor  Technology Tutor  Music Tutor   \n",
      "0            0              0             0                 1            0  \\\n",
      "34           0              0             0                 1            0   \n",
      "95           0              0             0                 1            0   \n",
      "28           0              0             0                 1            0   \n",
      "81           0              0             0                 1            0   \n",
      "94           0              0             0                 1            0   \n",
      "3            0              0             0                 1            0   \n",
      "41           0              0             0                 1            0   \n",
      "\n",
      "    Arts Tutor  Multimedia Tutor  Language Tutor  EXT1  EXT2  ...  CSN1  CSN2   \n",
      "0            0                 0               0     4     2  ...     5     4  \\\n",
      "34           0                 0               0     2     2  ...     4     4   \n",
      "95           0                 0               0     2     1  ...     5     5   \n",
      "28           0                 0               0     1     3  ...     3     3   \n",
      "81           0                 0               0     1     4  ...     3     3   \n",
      "94           0                 0               0     3     3  ...     4     2   \n",
      "3            0                 0               0     3     4  ...     2     3   \n",
      "41           0                 0               0     3     2  ...     4     2   \n",
      "\n",
      "    CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4  OPN5  \n",
      "0      4     5     5     4     4     2     4     4  \n",
      "34     4     5     5     4     4     3     5     4  \n",
      "95     5     5     5     5     5     4     5     4  \n",
      "28     4     3     4     3     3     2     4     3  \n",
      "81     4     4     2     2     4     3     3     3  \n",
      "94     3     3     3     3     3     2     4     3  \n",
      "3      2     3     4     3     2     3     4     3  \n",
      "41     2     3     3     2     2     3     4     4  \n",
      "\n",
      "[8 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "matchmaking(0, match_array, clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Index: 58\n",
      "Matched Peers:\n",
      "Index: 25 | Score: 78.81%\n",
      "Index: 5 | Score: 68.11%\n",
      "Index: 83 | Score: 56.30%\n",
      "Index: 92 | Score: 45.85%\n",
      "Index: 8 | Score: 41.01%\n",
      "Index: 13 | Score: 28.18%\n",
      "Index: 57 | Score: 24.33%\n",
      "\n",
      "                 Names Genders Age Ranges          Specialization  Categories\n",
      "58     Alyzar Aviandi     Male      17-25          Penulisan Buku  Multimedia\n",
      "25              Elma N  Female      17-25                   Excel  Multimedia\n",
      "5              Maulani  Female      17-25               Fotografi  Multimedia\n",
      "83          Dhea Setya  Female      17-25  Videografi dan Editing  Multimedia\n",
      "92                 Féi  Female      17-25            Editing Foto  Multimedia\n",
      "8                   JJ  Female      17-25              Videografi  Multimedia\n",
      "13  Bayu Daru Isnandar    Male      17-25            Audio Mixing  Multimedia\n",
      "57             kartika  Female      17-25        Microsoft Office  Multimedia\n",
      "\n",
      "    Math Tutor  Science Tutor  Social Tutor  Technology Tutor  Music Tutor   \n",
      "58           0              0             0                 0            0  \\\n",
      "25           0              0             0                 0            0   \n",
      "5            0              0             0                 0            0   \n",
      "83           0              0             0                 0            0   \n",
      "92           0              0             0                 0            0   \n",
      "8            0              0             0                 0            0   \n",
      "13           0              0             0                 0            0   \n",
      "57           0              0             0                 0            0   \n",
      "\n",
      "    Arts Tutor  Multimedia Tutor  Language Tutor  EXT1  EXT2  ...  CSN1  CSN2   \n",
      "58           0                 1               0     1     2  ...     2     3  \\\n",
      "25           0                 1               0     3     3  ...     3     3   \n",
      "5            0                 1               0     2     3  ...     4     4   \n",
      "83           0                 1               0     3     4  ...     4     3   \n",
      "92           0                 1               0     3     3  ...     4     2   \n",
      "8            0                 1               0     2     3  ...     3     2   \n",
      "13           0                 1               0     3     4  ...     2     3   \n",
      "57           0                 1               0     4     4  ...     4     4   \n",
      "\n",
      "    CSN3  CSN4  CSN5  OPN1  OPN2  OPN3  OPN4  OPN5  \n",
      "58     3     3     3     2     2     2     3     3  \n",
      "25     4     3     3     2     2     2     3     2  \n",
      "5      3     4     4     3     3     2     3     3  \n",
      "83     4     2     3     3     3     4     3     3  \n",
      "92     4     4     4     3     4     2     4     4  \n",
      "8      2     2     3     5     4     3     5     4  \n",
      "13     3     3     4     3     5     3     3     5  \n",
      "57     5     5     5     4     4     3     3     4  \n",
      "\n",
      "[8 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "matchmaking(58, match_array, clean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
